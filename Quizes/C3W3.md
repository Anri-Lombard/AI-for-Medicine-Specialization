# ML Interpretation

1. You train the random forest pictured below and it gets a c-index of 0.90. After shuffling the values for x, your dataset is the following. What is the variable importance for x?
   - 0.65

2. Say you have trained a decision tree which never splits on a variable X. What will be the variable importance for X using the permutation method?
   - 0 (_Using the permutation method, variable importance is calculated as the decrease in performance when the feature's values are shuffled. If the decision tree never splits on variable X, shuffling the values of X will have no effect on the model's performance, and the variable importance for X will be 0._)

3. We have the following table the output of a model f on an example using subsets of the variable. What is the Shapley value for s_BP?
   - 0.125

4. We have the following table the output of a model f on an example using subsets of the variable. What is the sum of the Shapley value for s_BP and d_BP?
   - 0.15

5. Could the following table of outputs be given by a linear model with no interactions (assume not including a feature means setting it to 0)?
   - No

6. Now assume we add Age as a variable. What is the new Shapley value for s_BP?
   - 0.09
